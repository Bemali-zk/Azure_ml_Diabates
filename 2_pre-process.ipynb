{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "src folder created\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1719886278543
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/data_preprocess.py\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--data\", type=str, help=\"Path to the input dataset\")\n",
        "    parser.add_argument(\"--output\", type=str, help=\"Path to save the processed dataset\")\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "def preprocess_data(input_path, output_path):\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(input_path)\n",
        "    \n",
        "    cols_num = ['age', 'HbA1c_level','bmi', 'blood_glucose_level']\n",
        "    cols_cat = ['gender','smoking_history']\n",
        "\n",
        "    # Replace numercial null values with the median\n",
        "    df[cols_num] = df[cols_num].fillna(df[cols_num].median())\n",
        "    \n",
        "    # Handle categorical variables\n",
        "    # One-hot encode 'smoking_history'\n",
        "    df = pd.get_dummies(df, columns=cols_cat, drop_first=True)   \n",
        "    \n",
        "    \n",
        "    # Standardization of numerical features\n",
        "    scaler = StandardScaler()\n",
        "    df[cols_num] = scaler.fit_transform(df[cols_num])\n",
        "    \n",
        "    # Handling outliers by clipping them to 1.5 times the interquartile range\n",
        "    Q1 = df[cols_num].quantile(0.25)\n",
        "    Q3 = df[cols_num].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    \n",
        "    for column in cols_num:\n",
        "        df[column] = np.clip(df[column], lower_bound[column], upper_bound[column])\n",
        "   \n",
        "    # Convert boolean columns to 1 and 0\n",
        "    bool_columns = df.select_dtypes(include=['bool']).columns\n",
        "    df[bool_columns] = df[bool_columns].astype(int)\n",
        "\n",
        "    \n",
        "    # Save the processed dataset\n",
        "    df.to_csv(output_path, index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    args = parse_args()\n",
        "    \n",
        "    preprocess_data(args.data, args.output)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting src/data_preprocess.py\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient, command, Input, Output\n",
        "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# Initialize MLClient using DefaultAzureCredential\n",
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential())\n",
        "\n",
        "# Get the dataset asset from Azure ML workspace\n",
        "data_asset = ml_client.data.get(\"Diabetes_Dataset\", version=\"1\")\n",
        "\n",
        "# Define the command job to run the Python script\n",
        "job = command(\n",
        "    code =\"./src\",# Path where the preprocess.py script is located\n",
        "    command='python data_preprocess.py --data \"${{inputs.data}}\" --output \"${{outputs.processed_data}}\"',\n",
        "    inputs={\n",
        "        \"data\": Input(\n",
        "            path=data_asset.id,\n",
        "            type=AssetTypes.URI_FILE,\n",
        "            mode=InputOutputModes.RO_MOUNT\n",
        "        )\n",
        "    },\n",
        "    outputs={\n",
        "        \"processed_data\": Output(\n",
        "            type=AssetTypes.URI_FILE,\n",
        "            mode=InputOutputModes.RW_MOUNT\n",
        "        )\n",
        "    },\n",
        "    environment=\"test-env-azureml:1\",# Ensure this environment has all required dependencies\n",
        "    compute=\"test-compute-1-mlstudio\",\n",
        "      \n",
        "      \n",
        ")\n",
        "\n",
        "# Create or update the job in Azure ML\n",
        "returned_job = ml_client.jobs.create_or_update(job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n\u001b[32mUploading src (0.0 MBs): 100%|██████████| 4896/4896 [00:00<00:00, 42826.78it/s]\n\u001b[39m\n\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719886385387
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Monitor your job at https://ml.azure.com/runs/gentle_island_3055db9n2m?wsid=/subscriptions/3b7a65ed-df6d-4020-9010-5585f2149752/resourcegroups/rg-test-1/workspaces/mlstudio-test-1&tid=dc0b52a3-68c5-44f7-881d-9383d8850b96\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719886385488
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}