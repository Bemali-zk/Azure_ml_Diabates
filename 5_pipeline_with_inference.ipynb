{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "src folder created\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719889275744
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/train-model-mlflow-sg.py\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # feature selection and split data  \n",
        "    feature_list = ['age','hypertension','heart_disease','bmi','HbA1c_level','blood_glucose_level']\n",
        "    target = 'diabetes'\n",
        "    X_train, X_test, y_train, y_test, df_test = split_data(df, feature_list,target)\n",
        "\n",
        "    # Save the test dataset\n",
        "    df_test.to_csv(args.test_dataset, index=False)\n",
        "\n",
        "    # train model\n",
        "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # evaluate model\n",
        "    eval_model(model, X_test, y_test)\n",
        "\n",
        "    #get model URI\n",
        "    mlflow.sklearn.log_model(model, \"model\")\n",
        "    model_uri = mlflow.get_artifact_uri(\"model\")\n",
        "    # Write the model URI to a file\n",
        "    with open(args.model_uri, \"w\") as f:\n",
        "        f.write(model_uri)\n",
        "    #save model\n",
        "    mlflow.sklearn.save_model(model, args.model_output)\n",
        "\n",
        "   \n",
        "\n",
        "def get_data(path):\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(path)\n",
        "    return df\n",
        "\n",
        "def split_data(df, feature_list,target):\n",
        "    print(\"Splitting data...\")\n",
        "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "    X_train, y_train = df_train[feature_list].values, df_train[target].values\n",
        "    X_test, y_test = df_test[feature_list].values, df_test[target].values\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test, df_test\n",
        "\n",
        "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
        "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
        "    print(\"Training model...\")\n",
        "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "    \n",
        "    return model\n",
        "\n",
        "def eval_model(model, X_test, y_test):\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        "    mlflow.log_metric(\"Accuracy\", acc)\n",
        "\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "    auc = roc_auc_score(y_test, y_scores[:,1])\n",
        "    print('AUC: ' + str(auc))\n",
        "    mlflow.log_metric(\"AUC\", auc)\n",
        "\n",
        "    # plot ROC curve and log as an artifact\n",
        "    plot_roc_curve(y_test, y_scores)\n",
        "\n",
        "def plot_roc_curve(y_test, y_scores):\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    roc_curve_path = \"ROC-Curve.png\"\n",
        "    plt.savefig(roc_curve_path)\n",
        "    mlflow.log_artifact(roc_curve_path)\n",
        "    plt.close(fig)\n",
        "\n",
        "def log_model(model):\n",
        "    mlflow.sklearn.log_model(model, \"model\")\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--training_data\", dest='training_data', type=str)\n",
        "    parser.add_argument(\"--reg_rate\", dest='reg_rate', type=float, default=0.01)\n",
        "    parser.add_argument(\"--model_output\", dest='model_output',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--model_uri\", dest='model_uri', type=str, required=True)\n",
        "    parser.add_argument(\"--test_dataset\",dest='test_dataset',type=str, required=True)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "    args = parse_args()\n",
        "    main(args)\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting src/train-model-mlflow-sg.py\n"
        }
      ],
      "execution_count": 25,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/infer.py\n",
        "# import libraries\n",
        "import argparse\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "\n",
        "def main(args):\n",
        "    # Load the test dataset\n",
        "    test_data = pd.read_csv(args.test_dataset)\n",
        "    \n",
        "    # Load the model\n",
        "    model = mlflow.pyfunc.load_model(args.model_output)\n",
        "    \n",
        "    # Perform inference\n",
        "    feature_list = ['age','hypertension','heart_disease','bmi','HbA1c_level','blood_glucose_level']\n",
        "    X_test = test_data[feature_list]  \n",
        "    predictions = model.predict(X_test)\n",
        "    \n",
        "    # Save the scored dataset\n",
        "    test_data[\"predictions\"] = predictions\n",
        "    test_data.to_csv(args.scored_dataset, index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--model_output\", dest='model_output',type=str, required=True)\n",
        "    parser.add_argument(\"--test_dataset\", dest='test_dataset',type=str, required=True)\n",
        "    parser.add_argument(\"--scored_dataset\", dest='scored_dataset',type=str, required=True)\n",
        "    args = parser.parse_args()\n",
        "    main(args)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting src/infer.py\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient, command, Input, Output, dsl\n",
        "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# Initialize MLClient using DefaultAzureCredential\n",
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential())\n",
        "\n",
        "data_asset = ml_client.data.get(\"Diabetes_Dataset\", version=\"1\")\n",
        "\n",
        "\n",
        "\n",
        "# Define the data preprocessing job\n",
        "data_preprocess_job = command(\n",
        "    code =\"./src\",# Path where the preprocess.py script is located\n",
        "    command='python data_preprocess.py --data \"${{inputs.data}}\" --output \"${{outputs.processed_data}}\"',\n",
        "    inputs={\n",
        "        \"data\": Input(\n",
        "            path=data_asset.id,\n",
        "            type=AssetTypes.URI_FILE,\n",
        "            mode=InputOutputModes.RO_MOUNT\n",
        "        )\n",
        "    },\n",
        "    outputs={\n",
        "        \"processed_data\": Output(\n",
        "            type=AssetTypes.URI_FILE,\n",
        "            mode=InputOutputModes.RW_MOUNT\n",
        "        )\n",
        "    },\n",
        "    environment=\"test-env-azureml:1\",# Ensure this environment has all required dependencies\n",
        "    compute=\"test-compute-1-mlstudio\",  \n",
        "      \n",
        ")\n",
        "\n",
        "# Define the model training job\n",
        "model_training_job = job = command(\n",
        "    code =\"./src\",# Path where the preprocess.py script is located\n",
        "    command='python train-model-mlflow-sg.py --training_data ${{inputs.data}} --model_output ${{outputs.model_output}} --model_uri ${{outputs.model_uri}} --test_dataset ${{outputs.test_dataset}}',\n",
        "    inputs={\n",
        "        \"data\": Input(\n",
        "            type=AssetTypes.URI_FILE,\n",
        "            mode=InputOutputModes.RO_MOUNT\n",
        "        )\n",
        "    },\n",
        "    outputs={\n",
        "        \"model_output\": Output(\n",
        "            type=AssetTypes.MLFLOW_MODEL,\n",
        "            mode=InputOutputModes.RW_MOUNT\n",
        "        ),\n",
        "        \"model_uri\": Output(\n",
        "            type=AssetTypes.URI_FILE,\n",
        "            mode=InputOutputModes.RW_MOUNT\n",
        "        ),\n",
        "        \"test_dataset\": Output(\n",
        "            type=AssetTypes.URI_FILE,\n",
        "            mode=InputOutputModes.RW_MOUNT\n",
        "        )\n",
        "    },\n",
        "\n",
        "    \n",
        "    environment=\"test-env-azureml:1\",# Ensure this environment has all required dependencies\n",
        "    compute=\"test-compute-1-mlstudio\",)\n",
        "\n",
        "#define inference script\n",
        "inference_job = command(\n",
        "    code=\"./src\",  # Path where the infer_model.py script is located\n",
        "    command='python infer.py  --model_output ${{inputs.model_output}} --test_dataset ${{inputs.test_dataset}} --scored_dataset ${{outputs.scored_dataset}}',\n",
        "    inputs={\n",
        "        \"model_output\": Input(\n",
        "            type=AssetTypes.MLFLOW_MODEL,\n",
        "            mode=InputOutputModes.RO_MOUNT\n",
        "        ),\n",
        "        \"test_dataset\": Input(\n",
        "            type=AssetTypes.URI_FILE,\n",
        "            mode=InputOutputModes.RO_MOUNT\n",
        "        )\n",
        "    },\n",
        "    outputs={\n",
        "        \"scored_dataset\": Output(\n",
        "            type=AssetTypes.URI_FILE,\n",
        "            mode=InputOutputModes.RW_MOUNT\n",
        "        )\n",
        "    },\n",
        "    environment=\"test-env-azureml:1\",  # Ensure this environment has all required dependencies\n",
        "    compute=\"test-compute-1-mlstudio\",\n",
        ")\n",
        "\n",
        "\n",
        "# Create a pipeline by combining the three jobs\n",
        "@dsl.pipeline(\n",
        "    description=\"Pipeline combining data preprocessing, model training and inference\",\n",
        "    default_compute=\"test-compute-1-mlstudio\"\n",
        ")\n",
        "def full_pipeline():\n",
        "    preprocess_step = data_preprocess_job()\n",
        "    train_step = model_training_job(\n",
        "        data=preprocess_step.outputs.processed_data)\n",
        "    infer_step = inference_job(\n",
        "        model_output=train_step.outputs.model_output,\n",
        "        test_dataset=train_step.outputs.test_dataset\n",
        "    )\n",
        "    \n",
        "    return{\n",
        "        \"pipeline_job_transformed_data\": preprocess_step.outputs.processed_data,\n",
        "        \"pipeline_job_trained_model\": train_step.outputs.model_output,\n",
        "        \"pipeline_job_scored_data\": infer_step.outputs.scored_dataset,\n",
        "    }\n",
        "\n",
        "\n",
        "pipeline = full_pipeline()\n",
        "\n",
        "# Submit the pipeline to Azure ML\n",
        "pipeline_job = ml_client.jobs.create_or_update(pipeline)\n",
        "aml_url = pipeline_job.studio_url\n",
        "print(\"Monitor your pipeline at\", aml_url)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\nUploading src (0.01 MBs): 100%|██████████| 9319/9319 [00:00<00:00, 67640.35it/s]\n\n\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Monitor your pipeline at https://ml.azure.com/runs/amusing_octopus_j9bcp177pr?wsid=/subscriptions/3b7a65ed-df6d-4020-9010-5585f2149752/resourcegroups/rg-test-1/workspaces/mlstudio-test-1&tid=dc0b52a3-68c5-44f7-881d-9383d8850b96\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719893024547
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}